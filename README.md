# Malware Classification with Hidden Markov Models and Support Vector Machines
<table>
  <tr>
    <td>HMM ROC curve for winwebsec vs zbot</td>
     <td>Stacked HMM and SVM ROC curve for winwebsec vs zbot</td>
  </tr>
  <tr>
    <td><img src="/images/winwebsec_vs_zbot_hmm_only.png" width=500 height=350></td>
    <td><img src="/images/winwebsec_vs_zbot_stacked_hmm_svm.png" width=500 height=350></td>
  </tr>
 </table>

This project is an implementation of a Hidden Markov Model (HMM) in java to classify malware families. Stacked HMMs and used Support Vector Machine (SVM) as a metaclassifier to improve the results. Used AUC as the main metric.

## HMM Introduction
HMMs are used to solve three main problems:
* Problem 1: Given the model λ = (A, B, π) and a sequence of observations O, find P(O | λ). Here, we
want to determine a score for the observed sequence O with respect to the given model λ.
* Problem 2: Given λ = (A, B, π) and an observation sequence O, find an optimal state sequence for the
underlying Markov process.
* Problem 3: Given an observation sequence O and the dimensions N and M, find the model λ = (A, B, π)
that maximizes the probability of O.

## Dataset Description

The dataset Malicia contains 48 malware families. For this project, I only worked with winwebsec, zbot, and zeroAccess because those families had the majority of the samples. Each sample contained the extracted operational codes (opcodes) from the binaries of the malware sample.

## Experiments Performed

The opcodes were counted to determine which opcodes appeared most frequently in each of the malware families. The top M number of opcodes were used as a hyperparameter for the HMM. Each HMM was trained on 1200 samples and tested on 100 samples from the same family and 100 samples from the same different family. A total of six experiments were performed:
* winwebsec vs zbot
* winwebsec vs zeroAccess
* zbot vs winwebsec
* zbot vs zeroAccess
* zeroAccess vs winwebsec
* zeroAccess vs zbot

Due to computational limitations the observation sequence was limited to 70k. To determine the performance of the HMM, the area under the ROC curve was computed and displayed. To improve the classification results, three HMMs were stacked and used as an input as a feature vector into the SVM.

## Results

Using only HMMs to classifiy the malware samples yielded between 50% - 94% accuracy. But when stacking three HMMs together and using a SVM as a metaclassifier the results were between 85% - 100% accuracy.


## Project/File Structure

- "data" contains the data used for this project (Malicia)
- "featureVectors" contains the scores of the three stacked HMMs for each experiment
- "output" contains the saved HMMs, opcode counts, and testing results
- "app/src" contains the java code used to implement the HMM, do the preprocessing, and run the experiments
- "notebooks/concat.ipynb" conatains the python code to concatenate the CSV files to create feature vectors for SVM
- "notebooks/hmm_results.ipynb" contains the plotted ROC curves for the trained HMMs
- "notebooks/stacking_with_svm_results.ipynb" contains the results from used the stacked HMMs as inputs into the SVM.

### Dependencies

- Java 11
- pip install -r requirements.txt

### Running the code

After cloning/downloading the repo:

1. run "./gradlew run" -> this will run experiments.BestNM
2. run "./gradlw createFV" -> this will run experiments.FeatureVectors
3. run the code in "notebooks/concat.ipynb" -> this will create the "featureVectors" directory
4. run/view "notebooks/hmm_results" and "notebooks/stacking_with_svm_results.ipynb"

Note: if you just want to see the results without running the code you can just view the jupyter notebooks in "notebooks"

## Author

Brandon Morimoto, undergraduate at San Jose State University

## Acknowledgments
HMM implementation based off of [A Revealing Introduction to Hidden Markov Models](http://www.cs.sjsu.edu/faculty/stamp/RUA/HMM.pdf) by Mark Stamp SJSU.

## Future Work

- Perform more rigorous experiments to find the best N and M for the HMMs.
- Try stacking more HMMs to feed into the SVM.
- Also, try other classification models as the metaclassifier.
